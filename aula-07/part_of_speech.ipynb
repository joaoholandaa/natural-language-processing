{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**CORPORA**"
      ],
      "metadata": {
        "id": "8qhw87ThE84t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mac-Morpho (NILC)**"
      ],
      "metadata": {
        "id": "J-IV1PutE3GJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BptbLoDfEMsZ",
        "outputId": "337313dd-01e4-4244-e127-8511f7cdb1e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-25 20:28:56--  http://nilc.icmc.usp.br/macmorpho/macmorpho-v3.tgz\n",
            "Resolving nilc.icmc.usp.br (nilc.icmc.usp.br)... 143.107.183.225\n",
            "Connecting to nilc.icmc.usp.br (nilc.icmc.usp.br)|143.107.183.225|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2463485 (2.3M) [application/x-gzip]\n",
            "Saving to: ‘macmorpho-v3.tgz’\n",
            "\n",
            "macmorpho-v3.tgz    100%[===================>]   2.35M  2.19MB/s    in 1.1s    \n",
            "\n",
            "2023-04-25 20:28:58 (2.19 MB/s) - ‘macmorpho-v3.tgz’ saved [2463485/2463485]\n",
            "\n",
            "macmorpho-dev.txt\n",
            "macmorpho-test.txt\n",
            "macmorpho-train.txt\n"
          ]
        }
      ],
      "source": [
        "!wget http://nilc.icmc.usp.br/macmorpho/macmorpho-v3.tgz\n",
        "!tar zxvf macmorpho-v3.tgz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('macmorpho-train.txt') as f:\n",
        "  doc = f.read().split('\\n')\n",
        "\n",
        "traindata = []\n",
        "for linha in doc:\n",
        "  sentenca = [tuple(par.split('_')) for par in linha.split()]\n",
        "  traindata.append(sentenca)\n",
        "\n",
        "with open('macmorpho-dev.txt') as f:\n",
        "  doc = f.read().split('\\n')\n",
        "\n",
        "devdata = []\n",
        "for linha in doc:\n",
        "  sentenca = [tuple(par.split('_')) for par in linha.split()]\n",
        "  devdata.append(sentenca)\n",
        "\n",
        "with open('macmorpho-test.txt') as f:\n",
        "  doc = f.read().split('\\n')\n",
        "\n",
        "testdata = []\n",
        "for linha in doc:\n",
        "  sentenca = [tuple(par.split('_')) for par in linha.split()]\n",
        "  testdata.append(sentenca)\n",
        "\n",
        "corpus = traindata + devdata + testdata"
      ],
      "metadata": {
        "id": "eEUXdhO7E2rl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[100]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdHwdt-RG7XO",
        "outputId": "fc8857e5-b3a6-410b-b6ea-4e10e97ae0ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('A', 'ART'),\n",
              " ('braquiária', 'N'),\n",
              " ('decunbens', 'ADJ'),\n",
              " ('só', 'PDEN'),\n",
              " ('fracassou', 'V'),\n",
              " ('na', 'PREP+ART'),\n",
              " ('Amazônia', 'NPROP'),\n",
              " ('e', 'KC'),\n",
              " ('é', 'V'),\n",
              " ('claro', 'ADJ'),\n",
              " ('não', 'ADV'),\n",
              " ('podia', 'V'),\n",
              " ('se', 'PROPESS'),\n",
              " ('dar', 'V'),\n",
              " ('bem', 'ADV'),\n",
              " ('no', 'PREP+ART'),\n",
              " ('sul', 'NPROP'),\n",
              " ('.', 'PU')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOPUVSawHBmS",
        "outputId": "f806db43-0de7-4628-ffee-b80e3ade627f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "49934"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "tagset = []\n",
        "for snt in corpus:\n",
        "  for palavra in snt:\n",
        "    tagset.append(palavra[1])\n",
        "\n",
        "Counter(tagset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMKWrn5EHGhc",
        "outputId": "366b2e7d-9fe2-4ad2-a533-cbfd32e00c46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'N': 200977,\n",
              "         'V': 99621,\n",
              "         'PREP': 91314,\n",
              "         'CUR': 2473,\n",
              "         'NUM': 16181,\n",
              "         'PREP+ART': 58335,\n",
              "         'NPROP': 91765,\n",
              "         'PU': 138865,\n",
              "         'PROADJ': 15415,\n",
              "         'PRO-KS': 10919,\n",
              "         'ADJ': 43269,\n",
              "         'KC': 23366,\n",
              "         'ART': 68618,\n",
              "         'KS': 12099,\n",
              "         'PCP': 19548,\n",
              "         'ADV': 24814,\n",
              "         'PROPESS': 11538,\n",
              "         'PREP+PROADJ': 1715,\n",
              "         'PDEN': 5666,\n",
              "         'PROSUB': 6381,\n",
              "         'PREP+PROPESS': 533,\n",
              "         'ADV-KS': 1041,\n",
              "         'PREP+PRO-KS': 219,\n",
              "         'PREP+PROSUB': 710,\n",
              "         'IN': 284,\n",
              "         'PREP+ADV': 85})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**UD_Portuguese-GSD**"
      ],
      "metadata": {
        "id": "0p9-SYiQHpBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/UniversalDependencies/UD_Portuguese-GSD.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHf1AMNzHnNl",
        "outputId": "21b2f50c-fe52-4f3d-bf61-0e5a9eb6b8e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'UD_Portuguese-GSD'...\n",
            "remote: Enumerating objects: 10394, done.\u001b[K\n",
            "remote: Counting objects: 100% (5634/5634), done.\u001b[K\n",
            "remote: Compressing objects: 100% (3233/3233), done.\u001b[K\n",
            "remote: Total 10394 (delta 3327), reused 3573 (delta 2401), pack-reused 4760\u001b[K\n",
            "Receiving objects: 100% (10394/10394), 31.41 MiB | 14.63 MiB/s, done.\n",
            "Resolving deltas: 100% (6728/6728), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def parse(fname):\n",
        "  with open(fname) as f:\n",
        "    doc = f.read()\n",
        "  doc = doc.split('\\n\\n')\n",
        "\n",
        "  snts = []\n",
        "  for j, inst in enumerate(doc[:-1]):\n",
        "    snt = []\n",
        "    rows = inst.split('\\n')\n",
        "    for i, elem in enumerate(rows):\n",
        "      if elem[0] != '#':\n",
        "        r = elem.split('\\t')\n",
        "        palavra, tag = r[1], r[3]\n",
        "        if tag != '_':\n",
        "          snt.append((palavra, tag))\n",
        "    snts.append(snt)\n",
        "  return snts\n",
        "\n",
        "path = 'UD_Portuguese-GSD/'\n",
        "\n",
        "traindata = parse(os.path.join(path, 'pt_gsd-ud-train.conllu'))\n",
        "devdata = parse(os.path.join(path, 'pt_gsd-ud-dev.conllu'))\n",
        "testdata = parse(os.path.join(path, 'pt_gsd-ud-test.conllu'))\n",
        "corpus = traindata + devdata + testdata"
      ],
      "metadata": {
        "id": "1l_07-PoIBrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bEWRodRrJmv-",
        "outputId": "dec8e756-e2c3-431d-9995-cf6020967b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12019"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBtMoLV_JtMR",
        "outputId": "1f17588d-0c3c-4778-e187-5b736c54ade1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('O', 'DET'),\n",
              " ('objetivo', 'NOUN'),\n",
              " ('de', 'ADP'),\n",
              " ('os', 'DET'),\n",
              " ('principais', 'ADJ'),\n",
              " ('hotéis', 'NOUN'),\n",
              " ('de', 'ADP'),\n",
              " ('a', 'DET'),\n",
              " ('cidade', 'NOUN'),\n",
              " ('é', 'AUX'),\n",
              " ('que', 'CCONJ'),\n",
              " ('o', 'DET'),\n",
              " ('hóspede', 'NOUN'),\n",
              " ('jamais', 'ADV'),\n",
              " ('tenha', 'AUX'),\n",
              " ('que', 'CCONJ'),\n",
              " ('sair', 'VERB'),\n",
              " ('dali', 'ADV'),\n",
              " ('e', 'CCONJ'),\n",
              " ('gaste', 'VERB'),\n",
              " ('a', 'ADP'),\n",
              " ('cada', 'DET'),\n",
              " ('minuto', 'NOUN'),\n",
              " ('de', 'ADP'),\n",
              " ('a', 'DET'),\n",
              " ('estadia', 'NOUN'),\n",
              " ('.', 'PUNCT')]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "tagset = []\n",
        "for snt in corpus:\n",
        "  for palavra in snt:\n",
        "    tagset.append(palavra[1])\n",
        "\n",
        "Counter(tagset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRGIdAEIJ4eh",
        "outputId": "b73f77f4-68be-4e09-d2c5-5f94e481203d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({'DET': 47520,\n",
              "         'NOUN': 56176,\n",
              "         'ADP': 51800,\n",
              "         'ADJ': 15057,\n",
              "         'AUX': 7343,\n",
              "         'CCONJ': 10953,\n",
              "         'ADV': 9750,\n",
              "         'VERB': 27484,\n",
              "         'PUNCT': 41902,\n",
              "         'PROPN': 32807,\n",
              "         'NUM': 8466,\n",
              "         'PRON': 7368,\n",
              "         'PART': 748,\n",
              "         'SYM': 1008,\n",
              "         'X': 531,\n",
              "         'SCONJ': 3})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Abordagem baseada em regras nas UD**"
      ],
      "metadata": {
        "id": "sB9G_NtvK-QX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "palavra2tag = {}\n",
        "\n",
        "treino = traindata + devdata\n",
        "for snt in treino:\n",
        "  for par in snt:\n",
        "    palavra = par[0].lower()\n",
        "    classe = par[1]\n",
        "    if palavra not in palavra2tag:\n",
        "      palavra2tag[palavra] = []\n",
        "    palavra2tag[palavra].append(classe)\n",
        "\n",
        "for palavra in palavra2tag:\n",
        "  tag_count = Counter(palavra2tag[palavra])\n",
        "  most_frequent = sorted(tag_count.items(), key=lambda x: x[1], reverse=True)[0][0]\n",
        "  palavra2tag[palavra] = most_frequent"
      ],
      "metadata": {
        "id": "7nwwa6l9K9om"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "palavra2tag['hotel']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fjjigOSVLQVi",
        "outputId": "a9f6c334-fb9b-41f5-851d-a74755adfad6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'NOUN'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "snt = 'O passado é só uma história que nos contamos.'.split()\n",
        "tags = []\n",
        "\n",
        "for token in snt:\n",
        "  try:\n",
        "    classe = palavra2tag[token.lower()]\n",
        "  except:\n",
        "    classe = 'NOUN'\n",
        "  tags.append(classe)\n",
        "\n",
        "[(w, tags[i]) for i, w in enumerate(snt)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVjjhoSvTOE0",
        "outputId": "13a6005c-ee7f-447f-98ec-42413395d067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('O', 'DET'),\n",
              " ('passado', 'ADJ'),\n",
              " ('é', 'AUX'),\n",
              " ('só', 'ADV'),\n",
              " ('uma', 'DET'),\n",
              " ('história', 'NOUN'),\n",
              " ('que', 'PRON'),\n",
              " ('nos', 'PRON'),\n",
              " ('contamos.', 'NOUN')]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Modelo Oculto de Márkov nas UD**"
      ],
      "metadata": {
        "id": "N40lJiwyT3kR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "from nltk.tag import hmm\n",
        "\n",
        "tagger = hmm.HiddenMarkovModelTrainer()\n",
        "tagger = tagger.train(traindata + devdata)"
      ],
      "metadata": {
        "id": "UOz_AwWTT6ey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tagger.tag('O passado é só uma história que nos contamos'.split())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vPss_8eUCNu",
        "outputId": "0c4aa27c-2db6-494b-9414-f9bb73db0dfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('O', 'DET'),\n",
              " ('passado', 'ADJ'),\n",
              " ('é', 'AUX'),\n",
              " ('só', 'ADV'),\n",
              " ('uma', 'DET'),\n",
              " ('história', 'NOUN'),\n",
              " ('que', 'PRON'),\n",
              " ('nos', 'PRON'),\n",
              " ('contamos', 'DET')]"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Redes Neurais Profundas**"
      ],
      "metadata": {
        "id": "f200Q9YjUZNL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Spacy**"
      ],
      "metadata": {
        "id": "s1qaU_RfUflv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -U pip setuptools wheel\n",
        "!pip3 install -U spacy[cuda102]\n",
        "!python3 -m spacy download pt_core_news_lg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ofi9Ubz8UfCf",
        "outputId": "485f245c-e41c-4dab-f193-fa47e3b994b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.9/dist-packages (23.0.1)\n",
            "Collecting pip\n",
            "  Downloading pip-23.1.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/dist-packages (0.40.0)\n",
            "Installing collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.0.1\n",
            "    Uninstalling pip-23.0.1:\n",
            "      Successfully uninstalled pip-23.0.1\n",
            "Successfully installed pip-23.1.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy[cuda102] in /usr/local/lib/python3.9/dist-packages (3.5.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy[cuda102]) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy[cuda102]) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy[cuda102]) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy[cuda102]) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy[cuda102]) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy[cuda102]) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy[cuda102]) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy[cuda102]) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy[cuda102]) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy[cuda102]) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy[cuda102]) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy[cuda102]) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy[cuda102]) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy[cuda102]) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy[cuda102]) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy[cuda102]) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy[cuda102]) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy[cuda102]) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy[cuda102]) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy[cuda102]) (3.3.0)\n",
            "Collecting cupy-cuda102<13.0.0,>=5.0.0b4 (from spacy[cuda102])\n",
            "  Downloading cupy_cuda102-12.0.0-cp39-cp39-manylinux2014_x86_64.whl (65.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.9/dist-packages (from cupy-cuda102<13.0.0,>=5.0.0b4->spacy[cuda102]) (0.8.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy[cuda102]) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda102]) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda102]) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda102]) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy[cuda102]) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy[cuda102]) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy[cuda102]) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy[cuda102]) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy[cuda102]) (2.1.2)\n",
            "Installing collected packages: cupy-cuda102\n",
            "Successfully installed cupy-cuda102-12.0.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m2023-04-25 21:35:56.036127: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-25 21:35:57.377138: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pt-core-news-lg==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_lg-3.5.0/pt_core_news_lg-3.5.0-py3-none-any.whl (568.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m568.2/568.2 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from pt-core-news-lg==3.5.0) (3.5.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->pt-core-news-lg==3.5.0) (2.1.2)\n",
            "Installing collected packages: pt-core-news-lg\n",
            "Successfully installed pt-core-news-lg-3.5.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_lg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "spacy.prefer_gpu()\n",
        "nlp = spacy.load('pt_core_news_lg')"
      ],
      "metadata": {
        "id": "uq5U-TsKUx_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp('O passado é só uma história que nos contamos.')"
      ],
      "metadata": {
        "id": "GvS__U6MVSkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "  print(token, token.pos_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8vAnnH0tVYwX",
        "outputId": "2408a8e4-5d4c-42a0-dc6a-7ee5668f5e06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O DET\n",
            "passado NOUN\n",
            "é AUX\n",
            "só ADV\n",
            "uma DET\n",
            "história NOUN\n",
            "que PRON\n",
            "nos PRON\n",
            "contamos VERB\n",
            ". PUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Avaliação**"
      ],
      "metadata": {
        "id": "ZngqS16OVprt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inicializando o córpus**"
      ],
      "metadata": {
        "id": "oIuevKPnVr_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def parse(fname):\n",
        "  with open(fname) as f:\n",
        "    doc = f.read()\n",
        "  doc = doc.split('\\n\\n')\n",
        "\n",
        "  snts = []\n",
        "  for j, inst in enumerate(doc[:-1]):\n",
        "    snt = []\n",
        "    rows = inst.split('\\n')\n",
        "    for i, elem in enumerate(rows):\n",
        "      if elem[0] != '#':\n",
        "        r = elem.split('\\t')\n",
        "        palavra, tag = r[1], r[3]\n",
        "        if tag != '_':\n",
        "          snt.append((palavra, tag))\n",
        "    snts.append(snt)\n",
        "  return snts\n",
        "\n",
        "path = 'UD_Portuguese-GSD/'\n",
        "\n",
        "traindata = parse(os.path.join(path, 'pt_gsd-ud-train.conllu'))\n",
        "devdata = parse(os.path.join(path, 'pt_gsd-ud-dev.conllu'))\n",
        "testdata = parse(os.path.join(path, 'pt_gsd-ud-test.conllu'))"
      ],
      "metadata": {
        "id": "wMuaYOSdVrGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Avaliação da Abordagem Baseada em Regras**"
      ],
      "metadata": {
        "id": "9WkiaaVyV95d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(corpus):\n",
        "  palavra2tag = {}\n",
        "  for snt in treino:\n",
        "    for w in snt:\n",
        "      palavra = w[0].lower()\n",
        "      if palavra not in palavra2tag:\n",
        "        palavra2tag[palavra] = []\n",
        "      palavra2tag[palavra].append(w[1])\n",
        "\n",
        "  for palavra in palavra2tag:\n",
        "    tag_count = Counter(palavra2tag[palavra])\n",
        "    most_frequent = sorted(tag_count.items(), key=lambda x: x[1], reverse=True)[0][0]\n",
        "    palavra2tag[palavra] = most_frequent\n",
        "  return palavra2tag\n",
        "\n",
        "def tag(tokens, palavra2tag):\n",
        "  tags = []\n",
        "  for token in tokens:\n",
        "    try:\n",
        "      tags.append(palavra2tag[token.lower()])\n",
        "    except:\n",
        "      tags.append('NOUN')\n",
        "  return tags\n",
        "\n",
        "palavra2tag = train(traindata + devdata)"
      ],
      "metadata": {
        "id": "pwMle5ixV7MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "y_real, y_pred = [], []\n",
        "for sentence in testdata:\n",
        "  tags = tag([w[0] for w in sentence], palavra2tag)\n",
        "  y_pred.extend(tags)\n",
        "\n",
        "  for (token, pos) in sentence:\n",
        "    y_real.append(pos)\n",
        "\n",
        "acc = accuracy_score(y_real, y_pred)\n",
        "print('Acurácia Abordagem Baseada em Regras: ', round(acc, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6VCsEfAWtmG",
        "outputId": "effd2b33-f41d-400f-fae7-ac32e31f4451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia Abordagem Baseada em Regras:  0.87\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Avaliação do Modelo Oculto de Márkov**"
      ],
      "metadata": {
        "id": "xEJn6w26Ytxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "from nltk.tag import hmm\n",
        "\n",
        "tagger = hmm.HiddenMarkovModelTrainer()\n",
        "tagger = tagger.train(traindata + devdata)"
      ],
      "metadata": {
        "id": "lw2CUnzQYbgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_real, y_pred = [], []\n",
        "for sentence in testdata:\n",
        "  tags = tagger.tag([w[0] for w in sentence])\n",
        "  y_pred.extend([w[1] for w in tags])\n",
        "\n",
        "  for (token, pos) in sentence:\n",
        "    y_real.append(pos)\n",
        "\n",
        "acc = accuracy_score(y_real, y_pred)\n",
        "print('Acurácia Modelo Oculto de Márkov: ', round(acc, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7Esdx9lY3l7",
        "outputId": "6fc202f3-dece-44ef-e37d-508444d60e76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia Modelo Oculto de Márkov:  0.51\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tagger.evaluate(testdata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYsie-3gc9YV",
        "outputId": "9b6df529-518b-4347-cba6-8acaec34d168"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-091b759ce55b>:1: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  tagger.evaluate(testdata)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5053015873015873"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Avaliação das Redes Neurais Profundas**"
      ],
      "metadata": {
        "id": "isEs_Qg8ddS8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "from spacy.tokens import Doc\n",
        "\n",
        "spacy.prefer_gpu()\n",
        "nlp = spacy.load('pt_core_news_lg')\n",
        "nlp.tokenizer = lambda x: Doc(nlp.vocab, words=x.split())\n",
        "\n",
        "y_real, y_pred = [], []\n",
        "for sentence in testdata:\n",
        "  for (token, pos) in sentence:\n",
        "    y_real.append(pos)\n",
        "\n",
        "  texto = ' '.join([w[0] for w in sentence])\n",
        "\n",
        "  doc = nlp(texto)\n",
        "  for token in doc:\n",
        "    y_pred.append(token.pos_)\n",
        "\n",
        "acc = accuracy_score(y_real, y_pred)\n",
        "print('Acurácia Redes Neurais: ', round(acc, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8NwpDbidgt2",
        "outputId": "fbb1a558-619b-4b3a-9e71-033197d76fdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Acurácia Redes Neurais:  0.92\n"
          ]
        }
      ]
    }
  ]
}
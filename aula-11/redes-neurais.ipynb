{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNV2r3h8QxGEfcfV4AqHbiA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **Aprenizagem de Máquina - Exemplo um-para-um**"],"metadata":{"id":"qz5kxVOggVqA"}},{"cell_type":"markdown","source":["## Demonstração 1 <br>\n","Treinando um modelo para prever verbos e substantivos\n"],"metadata":{"id":"uX_25bfogdlo"}},{"cell_type":"markdown","source":["### Importando as dependências"],"metadata":{"id":"2yBLjL5Pglpe"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"BpY5NQDhgUOu"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch import optim"]},{"cell_type":"markdown","source":["### Dados <br>\n","Redes Neurais lidam com números. Portanto, as strings devem ser convertidas em índices, tanto os nomes quanto as classes."],"metadata":{"id":"wfAziMI5gwAg"}},{"cell_type":"code","source":["#dados rotulados\n","X = [\n","    {'X': 'amar', 'y': 'verbo'},\n","    {'X': 'Ándre', 'y': 'substantivo'},\n","    {'X': 'beber', 'y': 'verbo'},\n","    {'X': 'Bárbara', 'y': 'substantivo'},\n","    {'X': 'Danilo', 'y': 'substantivo'},\n","    {'X': 'menino', 'y': 'verbo'},\n","    {'X': 'mulher', 'y': 'verbo'},\n","    {'X': 'sorrir', 'y': 'verbo'},\n","    {'X': 'Vivian', 'y': 'substantivo'},\n","    {'X': 'viver', 'y': 'verbo'},\n","]\n","\n","#Mapping de classe para índice e índice para classe\n","c2id = {'substantivo': 0, 'verbo': 1}\n","id2c = {0: 'substantivo', 1: 'verbo'}\n","\n","#Mapping de nome para índice e índice para nome\n","x2id = {w['X']:i for i, w in enumerate(X)}\n","#criação de um símbolo OOV (out of vocabulary) para nomes fora do conjunto de treinamento\n","x2id['oov'] = len(x2id)\n","id2x = {i:w for (w, i) in x2id.items()}\n","x2id"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LZdNVCM_gtIb","executionInfo":{"status":"ok","timestamp":1691418521806,"user_tz":180,"elapsed":13,"user":{"displayName":"João Pedro Holanda","userId":"16249923146655308797"}},"outputId":"65258886-48eb-4691-d95d-71dafe92fc12"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'amar': 0,\n"," 'Ándre': 1,\n"," 'beber': 2,\n"," 'Bárbara': 3,\n"," 'Danilo': 4,\n"," 'menino': 5,\n"," 'mulher': 6,\n"," 'sorrir': 7,\n"," 'Vivian': 8,\n"," 'viver': 9,\n"," 'oov': 10}"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","source":["### Modelo <br>\n","Desenvolvido com PyTorch"],"metadata":{"id":"DoKY-8B1seUo"}},{"cell_type":"code","source":["class Predictor(nn.Module):\n","  def __init__(self, inp_dim, n_classes, x2id):\n","    super(Predictor, self).__init__()\n","    self.x2id = x2id\n","    self.lookup = nn.Embedding(len(x2id), inp_dim)\n","    self.Wb = nn.Linear(inp_dim, n_classes)\n","    self.softmax = nn.LogSoftmax(1)\n","\n","  def forward(self, X):\n","    idxs = []\n","    for x in X:\n","      try:\n","        idxs.append(self.x2id[x])\n","      except:\n","        idxs.append(self.x2id['oov'])\n","    idxs = torch.tensor(idxs)\n","    embeddings = self.lookup(idxs)\n","    z = self.Wb(embeddings)\n","    return self.softmax(z)"],"metadata":{"id":"YFQGBVikr88Y"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Instanciando o modelo"],"metadata":{"id":"rG1VXzlit8b1"}},{"cell_type":"code","source":["inp_dim = 3\n","n_classes = len(c2id)\n","model = Predictor(inp_dim, n_classes, x2id)"],"metadata":{"id":"v9EnNMnVt7vk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Instanciando função de erro, otimizador e dados em lotes"],"metadata":{"id":"GjkmUppUuTiq"}},{"cell_type":"code","source":["nepochs = 10\n","batch_size = 2\n","batch_status = 2\n","learning_rate = 0.1\n","criterion = nn.NLLLoss()\n","optimizer = optim.AdamW(model.parameters(), lr=learning_rate)"],"metadata":{"id":"FIddl7VRuMHC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, Dataset\n","\n","traindata = DataLoader(X, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"vSyaBdz9us6X"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Treinamento"],"metadata":{"id":"JdggYiEwu7uT"}},{"cell_type":"code","source":["for epoch in range(nepochs):\n","  losses = []\n","  for batch_idx, row in enumerate(traindata):\n","    X = row['X']\n","    y = torch.tensor([c2id[c] for c in row['y']])\n","\n","    #forward\n","    outputs = model(X)\n","\n","    #calculate loss\n","    loss = criterion(outputs, y)\n","    losses.append(float(loss))\n","\n","    #backpropagation\n","    loss.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()\n","\n","    #diplay\n","    if (batch_idx+1) % batch_status == 0:\n","      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tTotal Loss: {:.6f}'.format(\n","                                                                                  epoch+1, batch_idx + 1, len(traindata),\n","                                                                                  100. * batch_idx / len(traindata), float(loss),\n","                                                                                  round(sum(losses) / len(losses), 5)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3DsHjWWju7DV","executionInfo":{"status":"ok","timestamp":1691418522160,"user_tz":180,"elapsed":360,"user":{"displayName":"João Pedro Holanda","userId":"16249923146655308797"}},"outputId":"0c96fc5f-7e27-4254-c317-e7e81cdaf095"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 [2/5 (20%)]\tLoss: 0.796322\tTotal Loss: 0.713820\n","Train Epoch: 1 [4/5 (60%)]\tLoss: 0.921497\tTotal Loss: 0.679870\n","Train Epoch: 2 [2/5 (20%)]\tLoss: 0.216533\tTotal Loss: 0.280030\n","Train Epoch: 2 [4/5 (60%)]\tLoss: 0.132326\tTotal Loss: 0.269270\n","Train Epoch: 3 [2/5 (20%)]\tLoss: 0.222173\tTotal Loss: 0.231490\n","Train Epoch: 3 [4/5 (60%)]\tLoss: 0.024899\tTotal Loss: 0.135900\n","Train Epoch: 4 [2/5 (20%)]\tLoss: 0.016874\tTotal Loss: 0.019080\n","Train Epoch: 4 [4/5 (60%)]\tLoss: 0.007456\tTotal Loss: 0.022890\n","Train Epoch: 5 [2/5 (20%)]\tLoss: 0.003020\tTotal Loss: 0.003880\n","Train Epoch: 5 [4/5 (60%)]\tLoss: 0.008095\tTotal Loss: 0.004810\n","Train Epoch: 6 [2/5 (20%)]\tLoss: 0.001627\tTotal Loss: 0.001390\n","Train Epoch: 6 [4/5 (60%)]\tLoss: 0.004090\tTotal Loss: 0.002220\n","Train Epoch: 7 [2/5 (20%)]\tLoss: 0.000761\tTotal Loss: 0.000890\n","Train Epoch: 7 [4/5 (60%)]\tLoss: 0.000825\tTotal Loss: 0.001030\n","Train Epoch: 8 [2/5 (20%)]\tLoss: 0.001024\tTotal Loss: 0.000570\n","Train Epoch: 8 [4/5 (60%)]\tLoss: 0.001550\tTotal Loss: 0.000810\n","Train Epoch: 9 [2/5 (20%)]\tLoss: 0.000437\tTotal Loss: 0.000680\n","Train Epoch: 9 [4/5 (60%)]\tLoss: 0.000980\tTotal Loss: 0.000700\n","Train Epoch: 10 [2/5 (20%)]\tLoss: 0.000444\tTotal Loss: 0.000640\n","Train Epoch: 10 [4/5 (60%)]\tLoss: 0.000068\tTotal Loss: 0.000560\n"]}]},{"cell_type":"markdown","source":["### Predição"],"metadata":{"id":"vPIS84pzzF7X"}},{"cell_type":"code","source":["val_X = [\"jogar\", \"amar\", \"cantar\", \"Vivian\"]\n","\n","outputs = model(val_X)\n","val_y = torch.argmax(outputs, 1).tolist()\n","\n","[id2c[c] for c in val_y]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tOMxDUZ7zIsD","executionInfo":{"status":"ok","timestamp":1691418522161,"user_tz":180,"elapsed":27,"user":{"displayName":"João Pedro Holanda","userId":"16249923146655308797"}},"outputId":"d312faa3-9e57-4fcf-d179-b736684333dd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['verbo', 'verbo', 'verbo', 'substantivo']"]},"metadata":{},"execution_count":48}]},{"cell_type":"markdown","source":["## Demonstração 2 <br>\n","Treinando um modelo para prever se um nome é masculino ou feminino"],"metadata":{"id":"R2i0VhMSQZ2y"}},{"cell_type":"markdown","source":["### Importando dependências"],"metadata":{"id":"hSOww_mgQl97"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch import optim\n","import nltk\n","from nltk.corpus import names\n","nltk.download()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rAIpKkGWQk_z","executionInfo":{"status":"ok","timestamp":1691418522162,"user_tz":180,"elapsed":21,"user":{"displayName":"João Pedro Holanda","userId":"16249923146655308797"}},"outputId":"d69c3fcf-08de-4c8c-85ee-513c6991de43"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package names to /root/nltk_data...\n","[nltk_data]   Package names is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":49}]},{"cell_type":"markdown","source":["### Dados"],"metadata":{"id":"3EwyVsJKQ2fJ"}},{"cell_type":"code","source":["from random import shuffle\n","masc = names.words('male.txt')\n","fem = names.words('female.txt')\n","\n","data = [{'X': row, 'y': 'male'} for row in masc]\n","data += [{'X': row, 'y': 'female'} for row in fem]\n","\n","name2id = {}\n","pos = 0\n","for name in data:\n","  if name['X'] not in name2id:\n","    name2id[name['X']] = pos\n","    pos += 1\n","name2id['oov'] = len(name2id.keys())\n","id2name = { i:name for (name, i) in name2id.items() }\n","\n","c2id = {'male': 0, 'female': 1}\n","id2c = {0: 'male', 1: 'female'}"],"metadata":{"id":"XlSos0NkQdNq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Separando dados de treino e teste"],"metadata":{"id":"ZmK5v6UdSQv-"}},{"cell_type":"code","source":["shuffle(data)\n","\n","size = int(len(data) * 0.2)\n","trainset = data[size:]\n","testset = data[:size]"],"metadata":{"id":"9FWB7td9SU29"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Modelo: Multi-layer Perceptron"],"metadata":{"id":"p_FtZDQkTWHT"}},{"cell_type":"code","source":["class NamePredictor(nn.Module):\n","  def __init__(self, inp_dim, hdim, n_classes, x2id):\n","    super(NamePredictor, self).__init__()\n","    self.x2id = x2id\n","    self.lookup = nn.Embedding(len(x2id), inp_dim)\n","    self.layer1 = nn.Linear(inp_dim, hdim)\n","    self.activation1 = nn.Sigmoid()\n","    self.layer2 = nn.Linear(hdim, n_classes)\n","    self.softmax = nn.LogSoftmax(1)\n","\n","  def forward(self, X):\n","    idxs = []\n","    for x in X:\n","      try:\n","        idxs.append(self.x2id[x])\n","      except:\n","        idxs.append(self.x2id['oov'])\n","    idxs = torch.tensor(idxs)\n","    embeddings = self.lookup(idxs)\n","\n","    z1 = self.layer1(embeddings)\n","    a1 = self.activation1(z1)\n","    z2 = self.layer2(a1)\n","    return self.softmax(z2)"],"metadata":{"id":"GeWtqOziTPM1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Inicializando o modelo"],"metadata":{"id":"F1SE4Tk-Uo6C"}},{"cell_type":"code","source":["inp_dim = 3\n","hdim = 10\n","n_classes = len(c2id)\n","model = NamePredictor(inp_dim, hdim, n_classes, name2id)"],"metadata":{"id":"rA7dCIzGUqqk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Instanciando função de erro, otimizadores e dados em lote"],"metadata":{"id":"eDHoPD1BVEbT"}},{"cell_type":"code","source":["nepochs = 20\n","batch_size = 16\n","batch_status = 64\n","learning_rate = 0.01\n","criterion = nn.NLLLoss()\n","optimizer = optim.AdamW(model.parameters(), lr=learning_rate)"],"metadata":{"id":"E4WgCeNzVDTW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, Dataset\n","\n","traindata = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n","testdata = DataLoader(testset, batch_size=batch_size, shuffle=True)"],"metadata":{"id":"PMYwlPUOVWZf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Método para avaliação"],"metadata":{"id":"ehQVt25jVi5U"}},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","\n","def evaluate(testdata):\n","  y_real, y_pred = [], []\n","  for batch_idx, row in enumerate(testdata):\n","    outputs = model(row['X'])\n","    y_pred.extend(torch.argmax(outputs, 1).tolist())\n","\n","    y_real.extend([c2id[c] for c in row['y']])\n","\n","  print('F1-Score:', f1_score(y_real, y_pred))"],"metadata":{"id":"zWZhtgXzVh79"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(nepochs):\n","  losses = []\n","  for batch_idx, row in enumerate(traindata):\n","    X = row['X']\n","    y = torch.tensor([c2id[c] for c in row['y']])\n","\n","    # Forward\n","    outputs = model(X)\n","\n","    # Calculate loss\n","    loss = criterion(outputs, y)\n","    losses.append(float(loss))\n","\n","    # Backpropagation\n","    loss.backward()\n","    optimizer.step()\n","    optimizer.zero_grad()\n","\n","    # Display\n","    if (batch_idx+1) % batch_status == 0:\n","      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tTotal Loss: {:.6f}'.format(\n","                            epoch+1, batch_idx + 1, len(traindata),\n","                            100. * batch_idx / len(traindata), float(loss),\n","                            round(sum(losses) / len(losses), 5)))\n","\n","  evaluate(testdata)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d3lOcw05WtIC","executionInfo":{"status":"ok","timestamp":1691418710050,"user_tz":180,"elapsed":10704,"user":{"displayName":"João Pedro Holanda","userId":"16249923146655308797"}},"outputId":"328ae9dd-40c7-4496-b66c-250fb320f7e7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 [64/398 (16%)]\tLoss: 0.550223\tTotal Loss: 0.663090\n","Train Epoch: 1 [128/398 (32%)]\tLoss: 0.755304\tTotal Loss: 0.663030\n","Train Epoch: 1 [192/398 (48%)]\tLoss: 0.762928\tTotal Loss: 0.660510\n","Train Epoch: 1 [256/398 (64%)]\tLoss: 0.673048\tTotal Loss: 0.663490\n","Train Epoch: 1 [320/398 (80%)]\tLoss: 0.637865\tTotal Loss: 0.661710\n","Train Epoch: 1 [384/398 (96%)]\tLoss: 0.668283\tTotal Loss: 0.659640\n","F1-Score: 0.7569471624266145\n","Train Epoch: 2 [64/398 (16%)]\tLoss: 0.683878\tTotal Loss: 0.655830\n","Train Epoch: 2 [128/398 (32%)]\tLoss: 0.631069\tTotal Loss: 0.658840\n","Train Epoch: 2 [192/398 (48%)]\tLoss: 0.648395\tTotal Loss: 0.657530\n","Train Epoch: 2 [256/398 (64%)]\tLoss: 0.620742\tTotal Loss: 0.652760\n","Train Epoch: 2 [320/398 (80%)]\tLoss: 0.658931\tTotal Loss: 0.654970\n","Train Epoch: 2 [384/398 (96%)]\tLoss: 0.703110\tTotal Loss: 0.654590\n","F1-Score: 0.7564604541895067\n","Train Epoch: 3 [64/398 (16%)]\tLoss: 0.677524\tTotal Loss: 0.616430\n","Train Epoch: 3 [128/398 (32%)]\tLoss: 0.594190\tTotal Loss: 0.615890\n","Train Epoch: 3 [192/398 (48%)]\tLoss: 0.504342\tTotal Loss: 0.610380\n","Train Epoch: 3 [256/398 (64%)]\tLoss: 0.730483\tTotal Loss: 0.610280\n","Train Epoch: 3 [320/398 (80%)]\tLoss: 0.639406\tTotal Loss: 0.608760\n","Train Epoch: 3 [384/398 (96%)]\tLoss: 0.566825\tTotal Loss: 0.609670\n","F1-Score: 0.6358267716535433\n","Train Epoch: 4 [64/398 (16%)]\tLoss: 0.527845\tTotal Loss: 0.514800\n","Train Epoch: 4 [128/398 (32%)]\tLoss: 0.437207\tTotal Loss: 0.490850\n","Train Epoch: 4 [192/398 (48%)]\tLoss: 0.560774\tTotal Loss: 0.483780\n","Train Epoch: 4 [256/398 (64%)]\tLoss: 0.321317\tTotal Loss: 0.483710\n","Train Epoch: 4 [320/398 (80%)]\tLoss: 0.384680\tTotal Loss: 0.484200\n","Train Epoch: 4 [384/398 (96%)]\tLoss: 0.657736\tTotal Loss: 0.485310\n","F1-Score: 0.6073774633653359\n","Train Epoch: 5 [64/398 (16%)]\tLoss: 0.300279\tTotal Loss: 0.315750\n","Train Epoch: 5 [128/398 (32%)]\tLoss: 0.387537\tTotal Loss: 0.321420\n","Train Epoch: 5 [192/398 (48%)]\tLoss: 0.190144\tTotal Loss: 0.316840\n","Train Epoch: 5 [256/398 (64%)]\tLoss: 0.329420\tTotal Loss: 0.321580\n","Train Epoch: 5 [320/398 (80%)]\tLoss: 0.350146\tTotal Loss: 0.322000\n","Train Epoch: 5 [384/398 (96%)]\tLoss: 0.173771\tTotal Loss: 0.316310\n","F1-Score: 0.5912144702842378\n","Train Epoch: 6 [64/398 (16%)]\tLoss: 0.157859\tTotal Loss: 0.181180\n","Train Epoch: 6 [128/398 (32%)]\tLoss: 0.305749\tTotal Loss: 0.184300\n","Train Epoch: 6 [192/398 (48%)]\tLoss: 0.054267\tTotal Loss: 0.175340\n","Train Epoch: 6 [256/398 (64%)]\tLoss: 0.190231\tTotal Loss: 0.174550\n","Train Epoch: 6 [320/398 (80%)]\tLoss: 0.073945\tTotal Loss: 0.180170\n","Train Epoch: 6 [384/398 (96%)]\tLoss: 0.102088\tTotal Loss: 0.187240\n","F1-Score: 0.5434663750683433\n","Train Epoch: 7 [64/398 (16%)]\tLoss: 0.065384\tTotal Loss: 0.107650\n","Train Epoch: 7 [128/398 (32%)]\tLoss: 0.059421\tTotal Loss: 0.113280\n","Train Epoch: 7 [192/398 (48%)]\tLoss: 0.030693\tTotal Loss: 0.109060\n","Train Epoch: 7 [256/398 (64%)]\tLoss: 0.239121\tTotal Loss: 0.115080\n","Train Epoch: 7 [320/398 (80%)]\tLoss: 0.107004\tTotal Loss: 0.117530\n","Train Epoch: 7 [384/398 (96%)]\tLoss: 0.115889\tTotal Loss: 0.122840\n","F1-Score: 0.5724751439037153\n","Train Epoch: 8 [64/398 (16%)]\tLoss: 0.040867\tTotal Loss: 0.081440\n","Train Epoch: 8 [128/398 (32%)]\tLoss: 0.045877\tTotal Loss: 0.078580\n","Train Epoch: 8 [192/398 (48%)]\tLoss: 0.132416\tTotal Loss: 0.086790\n","Train Epoch: 8 [256/398 (64%)]\tLoss: 0.102099\tTotal Loss: 0.088900\n","Train Epoch: 8 [320/398 (80%)]\tLoss: 0.121337\tTotal Loss: 0.092290\n","Train Epoch: 8 [384/398 (96%)]\tLoss: 0.017405\tTotal Loss: 0.097350\n","F1-Score: 0.5324459234608985\n","Train Epoch: 9 [64/398 (16%)]\tLoss: 0.043168\tTotal Loss: 0.075920\n","Train Epoch: 9 [128/398 (32%)]\tLoss: 0.006220\tTotal Loss: 0.078200\n","Train Epoch: 9 [192/398 (48%)]\tLoss: 0.043670\tTotal Loss: 0.082300\n","Train Epoch: 9 [256/398 (64%)]\tLoss: 0.012825\tTotal Loss: 0.086210\n","Train Epoch: 9 [320/398 (80%)]\tLoss: 0.036563\tTotal Loss: 0.087950\n","Train Epoch: 9 [384/398 (96%)]\tLoss: 0.212355\tTotal Loss: 0.090580\n","F1-Score: 0.5383342526199669\n","Train Epoch: 10 [64/398 (16%)]\tLoss: 0.060547\tTotal Loss: 0.062240\n","Train Epoch: 10 [128/398 (32%)]\tLoss: 0.057589\tTotal Loss: 0.064870\n","Train Epoch: 10 [192/398 (48%)]\tLoss: 0.035319\tTotal Loss: 0.073260\n","Train Epoch: 10 [256/398 (64%)]\tLoss: 0.111537\tTotal Loss: 0.077720\n","Train Epoch: 10 [320/398 (80%)]\tLoss: 0.218569\tTotal Loss: 0.079530\n","Train Epoch: 10 [384/398 (96%)]\tLoss: 0.205651\tTotal Loss: 0.085090\n","F1-Score: 0.5172608941709113\n","Train Epoch: 11 [64/398 (16%)]\tLoss: 0.079878\tTotal Loss: 0.075900\n","Train Epoch: 11 [128/398 (32%)]\tLoss: 0.003190\tTotal Loss: 0.080070\n","Train Epoch: 11 [192/398 (48%)]\tLoss: 0.268542\tTotal Loss: 0.077690\n","Train Epoch: 11 [256/398 (64%)]\tLoss: 0.007111\tTotal Loss: 0.078900\n","Train Epoch: 11 [320/398 (80%)]\tLoss: 0.117720\tTotal Loss: 0.081910\n","Train Epoch: 11 [384/398 (96%)]\tLoss: 0.094245\tTotal Loss: 0.081730\n","F1-Score: 0.5816485225505443\n","Train Epoch: 12 [64/398 (16%)]\tLoss: 0.005637\tTotal Loss: 0.058940\n","Train Epoch: 12 [128/398 (32%)]\tLoss: 0.110628\tTotal Loss: 0.070460\n","Train Epoch: 12 [192/398 (48%)]\tLoss: 0.005112\tTotal Loss: 0.066800\n","Train Epoch: 12 [256/398 (64%)]\tLoss: 0.126139\tTotal Loss: 0.075110\n","Train Epoch: 12 [320/398 (80%)]\tLoss: 0.102363\tTotal Loss: 0.077840\n","Train Epoch: 12 [384/398 (96%)]\tLoss: 0.164324\tTotal Loss: 0.080050\n","F1-Score: 0.48284023668639053\n","Train Epoch: 13 [64/398 (16%)]\tLoss: 0.144048\tTotal Loss: 0.052490\n","Train Epoch: 13 [128/398 (32%)]\tLoss: 0.197126\tTotal Loss: 0.063040\n","Train Epoch: 13 [192/398 (48%)]\tLoss: 0.099279\tTotal Loss: 0.064160\n","Train Epoch: 13 [256/398 (64%)]\tLoss: 0.171360\tTotal Loss: 0.069190\n","Train Epoch: 13 [320/398 (80%)]\tLoss: 0.010969\tTotal Loss: 0.072910\n","Train Epoch: 13 [384/398 (96%)]\tLoss: 0.189453\tTotal Loss: 0.077300\n","F1-Score: 0.5572192513368984\n","Train Epoch: 14 [64/398 (16%)]\tLoss: 0.081588\tTotal Loss: 0.054590\n","Train Epoch: 14 [128/398 (32%)]\tLoss: 0.135128\tTotal Loss: 0.059330\n","Train Epoch: 14 [192/398 (48%)]\tLoss: 0.151875\tTotal Loss: 0.067380\n","Train Epoch: 14 [256/398 (64%)]\tLoss: 0.143313\tTotal Loss: 0.067850\n","Train Epoch: 14 [320/398 (80%)]\tLoss: 0.122263\tTotal Loss: 0.071580\n","Train Epoch: 14 [384/398 (96%)]\tLoss: 0.012209\tTotal Loss: 0.077040\n","F1-Score: 0.4803337306317044\n","Train Epoch: 15 [64/398 (16%)]\tLoss: 0.004270\tTotal Loss: 0.054500\n","Train Epoch: 15 [128/398 (32%)]\tLoss: 0.041702\tTotal Loss: 0.057810\n","Train Epoch: 15 [192/398 (48%)]\tLoss: 0.046180\tTotal Loss: 0.057900\n","Train Epoch: 15 [256/398 (64%)]\tLoss: 0.131979\tTotal Loss: 0.065260\n","Train Epoch: 15 [320/398 (80%)]\tLoss: 0.054922\tTotal Loss: 0.070640\n","Train Epoch: 15 [384/398 (96%)]\tLoss: 0.065956\tTotal Loss: 0.072090\n","F1-Score: 0.619399310684392\n","Train Epoch: 16 [64/398 (16%)]\tLoss: 0.076022\tTotal Loss: 0.054760\n","Train Epoch: 16 [128/398 (32%)]\tLoss: 0.043888\tTotal Loss: 0.056370\n","Train Epoch: 16 [192/398 (48%)]\tLoss: 0.081135\tTotal Loss: 0.067490\n","Train Epoch: 16 [256/398 (64%)]\tLoss: 0.006470\tTotal Loss: 0.073190\n","Train Epoch: 16 [320/398 (80%)]\tLoss: 0.089852\tTotal Loss: 0.071160\n","Train Epoch: 16 [384/398 (96%)]\tLoss: 0.011186\tTotal Loss: 0.073600\n","F1-Score: 0.5331846068042387\n","Train Epoch: 17 [64/398 (16%)]\tLoss: 0.128110\tTotal Loss: 0.063160\n","Train Epoch: 17 [128/398 (32%)]\tLoss: 0.202192\tTotal Loss: 0.065270\n","Train Epoch: 17 [192/398 (48%)]\tLoss: 0.058323\tTotal Loss: 0.064070\n","Train Epoch: 17 [256/398 (64%)]\tLoss: 0.153178\tTotal Loss: 0.063330\n","Train Epoch: 17 [320/398 (80%)]\tLoss: 0.094855\tTotal Loss: 0.066950\n","Train Epoch: 17 [384/398 (96%)]\tLoss: 0.052232\tTotal Loss: 0.070810\n","F1-Score: 0.5544768069039915\n","Train Epoch: 18 [64/398 (16%)]\tLoss: 0.001507\tTotal Loss: 0.053600\n","Train Epoch: 18 [128/398 (32%)]\tLoss: 0.058814\tTotal Loss: 0.056770\n","Train Epoch: 18 [192/398 (48%)]\tLoss: 0.066154\tTotal Loss: 0.061670\n","Train Epoch: 18 [256/398 (64%)]\tLoss: 0.062985\tTotal Loss: 0.064270\n","Train Epoch: 18 [320/398 (80%)]\tLoss: 0.060526\tTotal Loss: 0.068500\n","Train Epoch: 18 [384/398 (96%)]\tLoss: 0.072314\tTotal Loss: 0.069050\n","F1-Score: 0.5014577259475218\n","Train Epoch: 19 [64/398 (16%)]\tLoss: 0.002003\tTotal Loss: 0.045730\n","Train Epoch: 19 [128/398 (32%)]\tLoss: 0.002507\tTotal Loss: 0.051020\n","Train Epoch: 19 [192/398 (48%)]\tLoss: 0.002863\tTotal Loss: 0.054120\n","Train Epoch: 19 [256/398 (64%)]\tLoss: 0.110936\tTotal Loss: 0.059820\n","Train Epoch: 19 [320/398 (80%)]\tLoss: 0.004028\tTotal Loss: 0.061720\n","Train Epoch: 19 [384/398 (96%)]\tLoss: 0.179873\tTotal Loss: 0.067850\n","F1-Score: 0.6297010607521697\n","Train Epoch: 20 [64/398 (16%)]\tLoss: 0.058287\tTotal Loss: 0.066550\n","Train Epoch: 20 [128/398 (32%)]\tLoss: 0.089493\tTotal Loss: 0.061810\n","Train Epoch: 20 [192/398 (48%)]\tLoss: 0.101843\tTotal Loss: 0.059610\n","Train Epoch: 20 [256/398 (64%)]\tLoss: 0.055949\tTotal Loss: 0.062720\n","Train Epoch: 20 [320/398 (80%)]\tLoss: 0.193282\tTotal Loss: 0.065590\n","Train Epoch: 20 [384/398 (96%)]\tLoss: 0.075994\tTotal Loss: 0.066000\n","F1-Score: 0.5513866231647635\n"]}]},{"cell_type":"markdown","source":["### Predição"],"metadata":{"id":"va5xfGNJby-z"}},{"cell_type":"code","source":["val_X = [\"Lucas\", \"Carlos\", \"Maria\", \"João\"]\n","\n","outputs = model(val_X)\n","val_y = torch.argmax(outputs, 1).tolist()\n","\n","[id2c[c] for c in val_y]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g4_04YiZaft2","executionInfo":{"status":"ok","timestamp":1691419083370,"user_tz":180,"elapsed":248,"user":{"displayName":"João Pedro Holanda","userId":"16249923146655308797"}},"outputId":"477eeaee-ee6c-42cb-fac9-705d144db119"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['male', 'female', 'female', 'male']"]},"metadata":{},"execution_count":70}]},{"cell_type":"markdown","source":["# **Análise de Sentimentos** <br>\n","B2W Digital é uma empresa de comércio eletrônico criada no final de 2006 pela fusão entre Submarino, Shoptime, Americanas.<br>\n","Neste exemplo, usaremos um córpus de revisão de produtos nestas plataformas. O objetivo é treinar um classificador para prever se uma revisão é boa, neutra ou ruim."],"metadata":{"id":"nBOHxvqPojOk"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","from torch import optim"],"metadata":{"id":"1PcUzpBMpBsH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Baixando o córpus"],"metadata":{"id":"Zy3m2g_EpIYP"}},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/b2wdigital/b2w-reviews01/master/B2W-Reviews01.csv"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pBRBFu8NpKm1","executionInfo":{"status":"ok","timestamp":1691506552341,"user_tz":180,"elapsed":1863,"user":{"displayName":"João Pedro Holanda","userId":"16249923146655308797"}},"outputId":"7c11f702-16f0-4963-da82-4a3bc8897e47"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-08-08 15:02:07--  https://raw.githubusercontent.com/b2wdigital/b2w-reviews01/master/B2W-Reviews01.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 49453175 (47M) [text/plain]\n","Saving to: ‘B2W-Reviews01.csv’\n","\n","B2W-Reviews01.csv   100%[===================>]  47.16M   290MB/s    in 0.2s    \n","\n","2023-08-08 15:02:09 (290 MB/s) - ‘B2W-Reviews01.csv’ saved [49453175/49453175]\n","\n"]}]},{"cell_type":"markdown","source":["## Carregando o córpus"],"metadata":{"id":"36YxUeg-phcz"}},{"cell_type":"code","source":["import csv\n","from random import shuffle\n","\n","with open('B2W-Reviews01.csv') as f:\n","  reader = csv.reader(f, delimiter=',', quotechar='\\\"')\n","  corpus = list(reader)\n","\n","  header, corpus = corpus[0], corpus[1:]\n","\n","shuffle(corpus)"],"metadata":{"id":"Xn9JhN-epfwk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Separando o córpus em conjuntos de treinamento e teste"],"metadata":{"id":"tQ-yLKh_pvCh"}},{"cell_type":"code","source":["size = int(len(corpus) * 0.2)\n","treino = corpus[size:]\n","teste = corpus[:size]\n","\n","len(treino), len(teste)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uPn6RweGpzWQ","executionInfo":{"status":"ok","timestamp":1691506667232,"user_tz":180,"elapsed":376,"user":{"displayName":"João Pedro Holanda","userId":"16249923146655308797"}},"outputId":"99b6c32f-e5cf-45ea-fc95-191ca7f3326e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(105899, 26474)"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["## Extraindo as features <br>\n","Como features, será utilizado informações do produto, como nome, marca e categoria: assim como informações da revisão do produto, como título e conteúdo.<br>\n","A partir destas informações, o objetivo é prever se a revisão do produto é boa, neutra ou ruim."],"metadata":{"id":"rdg3M3kSp3jt"}},{"cell_type":"code","source":["def get_features(info):\n","  product_id = info[2]\n","  product_name = info[3]\n","  product_brand = info[4]\n","  site_category_lv1 = info[5]\n","  site_category_lv2 = info[6]\n","  review_title = info[7]\n","  overall_rating = info[8]\n","  recommend_to_a_friend = info[9]\n","  review_text = info[10]\n","  reviewer_birth_year = info[11]\n","  reviewer_gender = info[12]\n","  reviewer_state = info[13]\n","\n","  x = ' '.join([product_name,\n","                product_brand,\n","                site_category_lv1,\n","                site_category_lv2,\n","                review_title,\n","                review_text])\n","  y = 2 if overall_rating in ['4', '5'] else 0 if overall_rating in ['1', '2'] else 1\n","  return { 'X': x, 'y': y }"],"metadata":{"id":"_3Pm0abdp69w"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Representação Vetorial TF-IDF\n","\n","Assim como aprendemos na aula anterior, o texto de entrada com as informações do produto e da revisão será codificado num vetor TF-IDF.\n","\n","Uma vez codificado, o vetor será passado para uma Regressão Logística que fará a classificação."],"metadata":{"id":"EI7IbXGYqjGh"}},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","stopwords = nltk.corpus.stopwords.words('portuguese')\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.pipeline import Pipeline\n","\n","def tokenize(texto):\n","  return nltk.word_tokenize(texto)\n","\n","pipe = Pipeline([\n","  ('count', CountVectorizer(tokenizer=tokenize, stop_words=stopwords, min_df=5)),\n","  ('tfidf', TfidfTransformer()),\n","])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qArmkQ81qkub","executionInfo":{"status":"ok","timestamp":1691507025540,"user_tz":180,"elapsed":25,"user":{"displayName":"João Pedro Holanda","userId":"16249923146655308797"}},"outputId":"f70c3ae7-0421-4377-8126-a0189cdabf59"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["## Treinando o modelo TF-IDF\n"],"metadata":{"id":"h4UjI_N4q0iF"}},{"cell_type":"code","source":["feat_treino = [get_features(w) for w in treino]\n","treino_X = [w['X'] for w in feat_treino]\n","treino_y = [w['y'] for w in feat_treino]\n","\n","pipe.fit(treino_X, treino_y)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":182},"id":"MKEw0JEbq3io","executionInfo":{"status":"ok","timestamp":1691507082987,"user_tz":180,"elapsed":54168,"user":{"displayName":"João Pedro Holanda","userId":"16249923146655308797"}},"outputId":"1687a64d-5f83-4bd2-f215-188847685b8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["Pipeline(steps=[('count',\n","                 CountVectorizer(min_df=5,\n","                                 stop_words=['a', 'à', 'ao', 'aos', 'aquela',\n","                                             'aquelas', 'aquele', 'aqueles',\n","                                             'aquilo', 'as', 'às', 'até', 'com',\n","                                             'como', 'da', 'das', 'de', 'dela',\n","                                             'delas', 'dele', 'deles', 'depois',\n","                                             'do', 'dos', 'e', 'é', 'ela',\n","                                             'elas', 'ele', 'eles', ...],\n","                                 tokenizer=<function tokenize at 0x7eee88d31d80>)),\n","                ('tfidf', TfidfTransformer())])"],"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;count&#x27;,\n","                 CountVectorizer(min_df=5,\n","                                 stop_words=[&#x27;a&#x27;, &#x27;à&#x27;, &#x27;ao&#x27;, &#x27;aos&#x27;, &#x27;aquela&#x27;,\n","                                             &#x27;aquelas&#x27;, &#x27;aquele&#x27;, &#x27;aqueles&#x27;,\n","                                             &#x27;aquilo&#x27;, &#x27;as&#x27;, &#x27;às&#x27;, &#x27;até&#x27;, &#x27;com&#x27;,\n","                                             &#x27;como&#x27;, &#x27;da&#x27;, &#x27;das&#x27;, &#x27;de&#x27;, &#x27;dela&#x27;,\n","                                             &#x27;delas&#x27;, &#x27;dele&#x27;, &#x27;deles&#x27;, &#x27;depois&#x27;,\n","                                             &#x27;do&#x27;, &#x27;dos&#x27;, &#x27;e&#x27;, &#x27;é&#x27;, &#x27;ela&#x27;,\n","                                             &#x27;elas&#x27;, &#x27;ele&#x27;, &#x27;eles&#x27;, ...],\n","                                 tokenizer=&lt;function tokenize at 0x7eee88d31d80&gt;)),\n","                (&#x27;tfidf&#x27;, TfidfTransformer())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;count&#x27;,\n","                 CountVectorizer(min_df=5,\n","                                 stop_words=[&#x27;a&#x27;, &#x27;à&#x27;, &#x27;ao&#x27;, &#x27;aos&#x27;, &#x27;aquela&#x27;,\n","                                             &#x27;aquelas&#x27;, &#x27;aquele&#x27;, &#x27;aqueles&#x27;,\n","                                             &#x27;aquilo&#x27;, &#x27;as&#x27;, &#x27;às&#x27;, &#x27;até&#x27;, &#x27;com&#x27;,\n","                                             &#x27;como&#x27;, &#x27;da&#x27;, &#x27;das&#x27;, &#x27;de&#x27;, &#x27;dela&#x27;,\n","                                             &#x27;delas&#x27;, &#x27;dele&#x27;, &#x27;deles&#x27;, &#x27;depois&#x27;,\n","                                             &#x27;do&#x27;, &#x27;dos&#x27;, &#x27;e&#x27;, &#x27;é&#x27;, &#x27;ela&#x27;,\n","                                             &#x27;elas&#x27;, &#x27;ele&#x27;, &#x27;eles&#x27;, ...],\n","                                 tokenizer=&lt;function tokenize at 0x7eee88d31d80&gt;)),\n","                (&#x27;tfidf&#x27;, TfidfTransformer())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(min_df=5,\n","                stop_words=[&#x27;a&#x27;, &#x27;à&#x27;, &#x27;ao&#x27;, &#x27;aos&#x27;, &#x27;aquela&#x27;, &#x27;aquelas&#x27;,\n","                            &#x27;aquele&#x27;, &#x27;aqueles&#x27;, &#x27;aquilo&#x27;, &#x27;as&#x27;, &#x27;às&#x27;, &#x27;até&#x27;,\n","                            &#x27;com&#x27;, &#x27;como&#x27;, &#x27;da&#x27;, &#x27;das&#x27;, &#x27;de&#x27;, &#x27;dela&#x27;, &#x27;delas&#x27;,\n","                            &#x27;dele&#x27;, &#x27;deles&#x27;, &#x27;depois&#x27;, &#x27;do&#x27;, &#x27;dos&#x27;, &#x27;e&#x27;, &#x27;é&#x27;,\n","                            &#x27;ela&#x27;, &#x27;elas&#x27;, &#x27;ele&#x27;, &#x27;eles&#x27;, ...],\n","                tokenizer=&lt;function tokenize at 0x7eee88d31d80&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfTransformer</label><div class=\"sk-toggleable__content\"><pre>TfidfTransformer()</pre></div></div></div></div></div></div></div>"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["nvocab = pipe.transform([\"Test\"]).shape[1]\n","nvocab"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hRKmAINJrT95","executionInfo":{"status":"ok","timestamp":1691507089687,"user_tz":180,"elapsed":423,"user":{"displayName":"João Pedro Holanda","userId":"16249923146655308797"}},"outputId":"2ab971f5-8923-4b35-a0e9-3904ea8eaa5e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["21723"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["## Regressão Logística"],"metadata":{"id":"J3dibVQarkh_"}},{"cell_type":"code","source":["class SentimentPredictor(nn.Module):\n","  def __init__(self, inp_dim, hdim, n_classes, tfidfer):\n","    super(SentimentPredictor, self).__init__()\n","    self.tfidfer = tfidfer\n","    self.layer1 = nn.Linear(inp_dim, hdim)\n","    self.activation1 = nn.Sigmoid()\n","    self.layer2 = nn.Linear(hdim, n_classes)\n","    self.softmax = nn.LogSoftmax(1)\n","\n","  def forward(self, X):\n","    tfidf = self.tfidfer.transform(X).toarray()\n","    tfidf = torch.tensor(tfidf).float()\n","\n","    z1 = self.layer1(tfidf)\n","    a1 = self.activation1(z1)\n","    z2 = self.layer2(a1)\n","    return self.softmax(z2)"],"metadata":{"id":"8c7-crS_rlpF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Inicializando o Modelo"],"metadata":{"id":"_pMK_A9ssjMu"}},{"cell_type":"code","source":["inp_dim = nvocab\n","hdim = 1024\n","n_classes = len(set(treino_y))\n","model = SentimentPredictor(inp_dim, hdim, n_classes, pipe)"],"metadata":{"id":"rKCHrYILskQy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Instanciando função de erro, otimizador e dados de treinamento e teste em lotes"],"metadata":{"id":"vhvNPvQOsmaC"}},{"cell_type":"code","source":["nepochs = 5\n","batch_size = 256\n","batch_status = 64\n","learning_rate = 0.01\n","criterion = nn.NLLLoss()\n","optimizer = optim.AdamW(model.parameters(), lr=learning_rate)"],"metadata":{"id":"dPXNNW-vsnbr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import DataLoader, Dataset\n","\n","traindata = DataLoader([get_features(x) for x in treino], batch_size=batch_size, shuffle=True)\n","testdata = DataLoader([get_features(x) for x in teste], batch_size=batch_size, shuffle=True)"],"metadata":{"id":"xeqkKrSzsqGp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Avaliação"],"metadata":{"id":"IK2X31Zpsu4q"}},{"cell_type":"code","source":["from sklearn.metrics import f1_score\n","\n","def evaluate(testdata):\n","  y_real, y_pred = [], []\n","  for batch_idx, row in enumerate(testdata):\n","    outputs = model(row['X'])\n","    y_pred.extend(torch.argmax(outputs, 1).tolist())\n","\n","    y_real.extend(row['y'])\n","\n","  print('F1-Score:', f1_score(y_real, y_pred, average='weighted'))"],"metadata":{"id":"QhmjI1oSswuV"},"execution_count":null,"outputs":[]}]}